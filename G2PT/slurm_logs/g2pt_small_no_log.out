============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
Overriding config with configs/datasets/aig.py:
dataset = 'aig'
vocab_size = 112 # Or use 106 if you prefer the exact count
block_size = 1024
data_dir = '../../datasets/aig/'
tokenizer_path = '../../tokenizers/aig/'

Overriding config with configs/networks/small.py:

n_layer = 6
n_head = 6
n_embd = 384
dropout = 0.0
bias = False
model_name = 'small'
Overriding: dataset = aig
Overriding: ordering = topo
Overriding: batch_size = 32
CUDA available. Using device: cuda
tokens per iteration will be: 1310720,40,1
Using dtype: bfloat16
Autocast context type: cuda, ptdtype: torch.bfloat16
Using topological sequence generation logic for AIG dataset.
DataLoader num_workers: 0
Initializing a new model from scratch
number of parameters: 10.66M
num decayed parameter tensors: 26, with 11,053,056 parameters
num non-decayed parameter tensors: 13, with 4,992 parameters
using fused AdamW: True
iter 0: loss 4.6577, time 3550.32ms, mfu -100.00%
iter 10: loss 3.6354, time 2997.60ms, mfu 12.94%
iter 20: loss 3.5794, time 3154.06ms, mfu 12.87%
iter 30: loss 3.4555, time 2996.27ms, mfu 12.88%
iter 40: loss 3.3144, time 3143.67ms, mfu 12.82%
iter 50: loss 3.1421, time 2976.02ms, mfu 12.84%
iter 60: loss 2.9923, time 3126.22ms, mfu 12.80%
iter 70: loss 2.7957, time 2972.33ms, mfu 12.82%
iter 80: loss 2.6894, time 3150.41ms, mfu 12.77%
iter 90: loss 2.4748, time 2993.26ms, mfu 12.79%
iter 100: loss 2.3795, time 2973.16ms, mfu 12.82%
iter 110: loss 2.2415, time 3002.86ms, mfu 12.83%
iter 120: loss 2.1231, time 3031.50ms, mfu 12.82%
iter 130: loss 2.1737, time 3013.89ms, mfu 12.83%
iter 140: loss 2.0292, time 3123.23ms, mfu 12.79%
iter 150: loss 1.9404, time 2979.60ms, mfu 12.81%
iter 160: loss 1.9600, time 3113.27ms, mfu 12.77%
iter 170: loss 1.8687, time 2952.03ms, mfu 12.81%
iter 180: loss 1.7886, time 3160.22ms, mfu 12.76%
iter 190: loss 1.6730, time 2997.71ms, mfu 12.77%
iter 200: loss 1.7325, time 3146.73ms, mfu 12.73%
iter 210: loss 1.6206, time 3006.80ms, mfu 12.75%
iter 220: loss 1.6415, time 3021.38ms, mfu 12.75%
iter 230: loss 1.6216, time 2998.42ms, mfu 12.77%
iter 240: loss 1.6374, time 3138.13ms, mfu 12.73%
iter 250: loss 1.5681, time 3000.46ms, mfu 12.75%
iter 260: loss 1.7141, time 3123.74ms, mfu 12.72%
iter 270: loss 1.5946, time 2998.82ms, mfu 12.74%
iter 280: loss 1.5626, time 3140.04ms, mfu 12.70%
iter 290: loss 1.5501, time 2962.07ms, mfu 12.74%
iter 300: loss 1.4910, time 3056.62ms, mfu 12.73%
iter 310: loss 1.4609, time 2981.53ms, mfu 12.76%
iter 320: loss 1.5218, time 3160.71ms, mfu 12.71%
iter 330: loss 1.5967, time 3070.74ms, mfu 12.70%
iter 340: loss 1.5102, time 3150.01ms, mfu 12.66%
iter 350: loss 1.4630, time 3001.31ms, mfu 12.69%
iter 360: loss 1.4487, time 3013.82ms, mfu 12.71%
iter 370: loss 1.4920, time 2986.10ms, mfu 12.73%
iter 380: loss 1.4028, time 3032.64ms, mfu 12.74%
iter 390: loss 1.4725, time 3039.03ms, mfu 12.74%
iter 400: loss 1.3918, time 3126.82ms, mfu 12.71%
iter 410: loss 1.3929, time 2989.85ms, mfu 12.73%
iter 420: loss 1.4185, time 3144.69ms, mfu 12.69%
iter 430: loss 1.3547, time 2992.21ms, mfu 12.72%
iter 440: loss 1.3876, time 3124.61ms, mfu 12.69%
iter 450: loss 1.3929, time 3010.28ms, mfu 12.71%
iter 460: loss 1.4052, time 3195.06ms, mfu 12.65%
iter 470: loss 1.3488, time 2982.36ms, mfu 12.69%
iter 480: loss 1.3361, time 3011.20ms, mfu 12.71%
iter 490: loss 1.3724, time 3017.62ms, mfu 12.72%
iter 500: loss 1.4766, time 3031.53ms, mfu 12.73%
iter 510: loss 1.3700, time 3017.52ms, mfu 12.74%
iter 520: loss 1.3391, time 3061.25ms, mfu 12.73%
iter 530: loss 1.3828, time 3002.70ms, mfu 12.75%
iter 540: loss 1.2914, time 2995.55ms, mfu 12.77%
iter 550: loss 1.3826, time 3020.42ms, mfu 12.78%
iter 560: loss 1.1938, time 3033.00ms, mfu 12.78%
iter 570: loss 1.3099, time 3016.99ms, mfu 12.78%
iter 580: loss 1.2320, time 3033.97ms, mfu 12.78%
iter 590: loss 1.2036, time 3010.02ms, mfu 12.79%
iter 600: loss 1.2487, time 3041.45ms, mfu 12.79%
iter 610: loss 1.2810, time 3042.69ms, mfu 12.78%
iter 620: loss 1.2593, time 3004.88ms, mfu 12.80%
iter 630: loss 1.2488, time 2999.64ms, mfu 12.81%
iter 640: loss 1.1765, time 3005.42ms, mfu 12.82%
iter 650: loss 1.1407, time 3026.48ms, mfu 12.82%
iter 660: loss 1.2596, time 3013.78ms, mfu 12.82%
iter 670: loss 1.3680, time 2975.82ms, mfu 12.84%
iter 680: loss 1.1821, time 3030.24ms, mfu 12.84%
iter 690: loss 1.0256, time 3030.10ms, mfu 12.83%
iter 700: loss 1.1258, time 3033.62ms, mfu 12.83%
iter 710: loss 1.0851, time 3027.00ms, mfu 12.83%
iter 720: loss 1.2576, time 3027.38ms, mfu 12.83%
iter 730: loss 1.2550, time 2998.61ms, mfu 12.84%
iter 740: loss 1.2452, time 3015.85ms, mfu 12.84%
iter 750: loss 1.2091, time 3000.07ms, mfu 12.85%
iter 760: loss 1.1976, time 2987.71ms, mfu 12.86%
iter 770: loss 1.1016, time 2988.77ms, mfu 12.87%
iter 780: loss 1.1595, time 2983.01ms, mfu 12.88%
iter 790: loss 1.0936, time 2986.36ms, mfu 12.89%
iter 800: loss 1.2042, time 3047.99ms, mfu 12.88%
iter 810: loss 1.2287, time 2982.63ms, mfu 12.89%
iter 820: loss 1.1119, time 3026.94ms, mfu 12.88%
iter 830: loss 1.1753, time 2999.50ms, mfu 12.89%
iter 840: loss 1.1848, time 2977.46ms, mfu 12.90%
iter 850: loss 0.9341, time 2980.12ms, mfu 12.91%
iter 860: loss 1.0709, time 2980.97ms, mfu 12.92%
iter 870: loss 1.1129, time 2989.27ms, mfu 12.93%
iter 880: loss 1.2585, time 3041.80ms, mfu 12.91%
iter 890: loss 0.9961, time 2996.08ms, mfu 12.91%
iter 900: loss 0.9590, time 3003.45ms, mfu 12.91%
iter 910: loss 1.0878, time 2978.12ms, mfu 12.92%
iter 920: loss 1.0536, time 3022.19ms, mfu 12.91%
iter 930: loss 1.0954, time 2981.97ms, mfu 12.92%
iter 940: loss 0.9872, time 2996.18ms, mfu 12.92%
iter 950: loss 1.1516, time 2996.41ms, mfu 12.93%
iter 960: loss 1.1353, time 3011.27ms, mfu 12.92%
iter 970: loss 1.0078, time 3007.19ms, mfu 12.92%
iter 980: loss 1.0059, time 2932.10ms, mfu 12.95%
iter 990: loss 1.0471, time 2964.80ms, mfu 12.96%
step 1000: train loss 1.0267, val loss 1.0367
saving checkpoint to results/None
Traceback (most recent call last):
  File "/gpfs/home6/igardner1/aig-gen/G2PT/train.py", line 379, in <module>
    torch.save(checkpoint, os.path.join(out_dir, 'ckpt.pt'))
  File "/home/igardner1/.conda/envs/g2pt-aig/lib/python3.10/site-packages/torch/serialization.py", line 943, in save
    with _open_zipfile_writer(f) as opened_zipfile:
  File "/home/igardner1/.conda/envs/g2pt-aig/lib/python3.10/site-packages/torch/serialization.py", line 810, in _open_zipfile_writer
    return container(name_or_buffer)
  File "/home/igardner1/.conda/envs/g2pt-aig/lib/python3.10/site-packages/torch/serialization.py", line 781, in __init__
    super().__init__(torch._C.PyTorchFileWriter(self.name, _compute_crc32))
RuntimeError: Parent directory results/None does not exist.
srun: error: gcn8: task 0: Exited with exit code 1
srun: Terminating StepId=11276355.0

JOB STATISTICS
==============
Job ID: 11276355
Cluster: snellius
User/Group: igardner1/igardner1
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 15:18:00 core-walltime
Job Wall-clock time: 00:51:00
Memory Utilized: 0.00 MB
Memory Efficiency: 0.00% of 120.00 GB (120.00 GB/node)
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
